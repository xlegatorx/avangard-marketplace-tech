#!/usr/bin/env python
# coding: utf-8

# ### Техническое задание

# Выполнение тестового задания для ООО Авангард на вакансию дата аналитик 
# 
# **Задание 1**
# 
#  а) Какие подгруппы товаров наиболее часто покупают за все время продаж (минимум 4 группы)?
#  
#  б) Какие подгруппы товаров наиболее часто покупают за последние два года (минимум 4 группы)?
#  
#  в) Какие подгруппы товаров наиболее часто покупают за последний год(минимум 4 группы)?
# 
#  Подгруппа – Sub-Category
#  Дата – Order_date
#  Сделать вывод на основе полученных результатов.
# 
#  **Задание 2**
#  Построить boxplot («Ящик с усами») на основе продаж (Sales). Найти мажоритарную черту (т.е. избавиться от аномалий и представить четкую картину распределения величин).
#  Можно использовать правило трех сигм. Однако любые другие решения приветствуются.
# 
#  **Задание 3**
#  Для этого задания необходимо разбить все покупки на энное количество групп “Sale_group” (Допустим маленькие продажи, средние и высокие) на основе Sales
# Сгруппировать данные на основе региона и группы продаж (Region, Sale_group). Определить основные тенденции и паттерны. Выделить наиболее «прибыльную» группу.
# 
#  Замечания: Работу лучше выполнить в jupyter и там же написать выводы по каждому заданию. После выполнения загрузите код на github.

# ### Импорт библиотек и онбординг

# In[199]:


import pandas as pd
from datetime import datetime
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px


# In[50]:


url = 'https://docs.google.com/spreadsheets/d/1DkdhWMrVjtflQfmCIKl8hCjSlIxph1L42_fgyFo0QPs/export?format=csv&gid=1477722452'


# In[51]:


df = pd.read_csv(url)


# In[52]:


def total_info(data):
    print('Ознакомление с датафреймом')
    print('')
    
    
    display(data.head())
    print('Получены первые 5 строк датафрейма')
    print('')
    
    size = 'Общее количество столбцов в датафрейме: {cols} Количество строк в датафрейме {rows}'
    size = size.format(cols = data.shape[1], rows = data.shape[0])
    print(size)
    print('')
    
    print(data.info())
    print('Получена основная информация о датафрейме')
    print('')
    
    missing_counts = data.isnull().sum()
    missing_percentage = round((data.isnull().sum() / len(data)) * 100,2)
    result_df = pd.DataFrame({'Количество пропусков': missing_counts, 'Процент пропусков': missing_percentage})
    result_df.index.name = 'Название столбца'
    result_df = result_df[result_df['Количество пропусков'] > 0]
    print('Датафрейм со столбцами, содержащими пропуски:')
    display(result_df.reset_index())
    print('')
    
    duplicated = 'Количество полностью дублирующихся строк: {duplicate} \nВ процентах {percent}'
    duplicated = duplicated.format(duplicate = data.duplicated().sum(),\
                                   percent = round(data.duplicated().sum() / data.shape[0] * 100,3))
    print(duplicated)


# In[53]:


total_info(df)


# После онбординга с датафреймом выявлено:
#     
#     - Датасет включает 9800 строк и 6 столбцов
#     - Названия столбцов не приведены к змеиному регистру
#     - Тип данных некоторых столбцов несоответствует хранящимся в нем данным
#     - В датасете нет пропущенных значений или явных дубликатов

# ### Предобработка данных

# #### Ренейм столбцов

# In[55]:


df.columns


# In[56]:


df = df.rename(columns = {'ID':'id',
                          'Order Date': 'order_date', 
                          'Class' : 'class',
                          'Region' : 'region',
                          'Sub-Category' : 'sub_category',
                          'Sales' : 'sales'})


# In[57]:


df.head()


# Названия столбцов приобрели змеиный регистр

# #### Коррекция типов данных столбцов и хранящейся в них информации

# In[58]:


df.info()


# In[63]:


df['order_date'] = pd.to_datetime(df['order_date'], format='%d/%m/%Y')
df['sales'] = df['sales'].str.replace(',', '.').astype(float)


# In[65]:


df.dtypes


# - Столбец order_date скорректирован и теперь хранит данные типа datetime64
# - Столбец sales так же изменен со строки на float64

# #### Проверка на наличие неявных дубликатов

# In[66]:


print(df['region'].value_counts())
print('-----------')
print(df['class'].value_counts())
print('-----------')
print(df['sub_category'].value_counts())


# Неявных дубликатов необнаружено

# #### Резюме предобработки

# - Столбцы приведены в змеиный регистр
# - Изменены типы данных некоторых столбцов
# - Выполнена перепроверка на наличие неявных дубликатов

# ### Анализ данных

# #### Задание 1

# In[124]:


df.sample(5)


# ##### Какие подгруппы товаров наиболее часто покупают за все время продаж (минимум 4 группы)?

# In[125]:


df_orders = df.groupby('sub_category', as_index = False).agg({'order_date':'count'})\
                                            .sort_values('order_date', ascending = False)\
                                            .rename(columns = {'order_date':'orders_number'})


# In[126]:


df_orders.head(5)


# Выделены топ 5 субкатегорий с наибольшим количеством заказов за все время

# #### Какие подгруппы товаров наиболее часто покупают за последние два года (минимум 4 группы)?
# 

# In[127]:


df.order_date.max()


# Последняя дата в исследуемых данных '2018-12-30', чтобы посмотреть какие подгрупны товаров наиболее часто покупали за последние два года нужно исходной датой взять '2016-12-30'

# In[128]:


df_last_two_years = df.query('order_date > "2016-12-30"').groupby('sub_category', as_index = False).agg({'order_date':'count'})\
                                            .sort_values('order_date', ascending = False)\
                                            .rename(columns = {'order_date':'orders_number_last_two_years'})


# In[129]:


df_last_two_years.head(5)


# Выделены топ 5 субкатегорий с наибольшим количеством заказов за последние 2 года исследуемых данных

# ##### Какие подгруппы товаров наиболее часто покупают за последний год(минимум 4 группы)

# In[130]:


df_last_year  = df.query('order_date > "2017-12-30"').groupby('sub_category', as_index = False).agg({'order_date':'count'})\
                                            .sort_values('order_date', ascending = False)\
                                            .rename(columns = {'order_date':'orders_number_last_year'})


# In[131]:


df_last_year.head(5)


# Выделены топ 5 субкатегорий с наибольшим количеством заказов за последний год исследуемых данных
# 

# ##### Вывод по заданию 1

# Во всех 3 исследуемых периодах субкатегории с наивысшим числом заказов совпадают, топ 5 всключает в себя: 'Binders', 'Paper', 'Furnishings', 'Phones', 'Storage'

# In[158]:


pivot_table = (pd.merge(df_orders, df_last_year, on='sub_category', how='outer')
               .merge(df_last_two_years, on='sub_category', how='outer'))


# Мердж всех 3 датасетов для получения финального датасета

# In[266]:


sub_categories_of_interest = ['Binders', 'Paper', 'Furnishings', 'Phones', 'Storage']
top_5_pivot_table = pivot_table[pivot_table['sub_category'].isin(sub_categories_of_interest)]
top_5_pivot_table.sort_values('orders_number',ascending = False)


# In[299]:


df_heatmap = top_5_pivot_table.set_index('sub_category')
plt.figure(figsize=(6, 6))
sns.heatmap(df_heatmap, cmap='YlGnBu', annot=True, fmt='g')
plt.xlabel('Количество заказов по временным интервалам')
plt.ylabel('Подкатегории')
plt.title('Тепловая карта заказов по субкатегориям')
plt.show()


# На тепловой карте отмечено количество заказов в разных субкатегориях в разбивке по временным периодам

# #### Дополнение: какой процент от всех заказов составляют заказы данных топ 5 категорий за все время

# In[163]:


all_orders = df.order_date.count()
all_orders


# In[171]:


df_copy = top_5_pivot_table.copy()

df_copy['percentage_of_total_orders'] = df_copy['orders_number'].apply(lambda x:round((x / all_orders) * 100, 2))

df_copy


# Создан столбец с данными, которые являются процентом заказов топ 5 субкатегорий за все время от общего числа заказов 

# #### Задание 2  Построить boxplot («Ящик с усами») на основе продаж (Sales). Найти мажоритарную черту (т.е. избавиться от аномалий и представить четкую картину распределения величин).
# 

# In[173]:


all_sales = df.sales.sum()
all_sales


# In[191]:


df.describe()


# In[212]:


sns.boxplot(data=df, y='sales', color='darkgreen', width=0.5)

plt.xlabel('Размах', fontsize=7)
plt.ylabel('Сумма', fontsize=7)
plt.title('Диаграмма размаха на основе продаж', fontsize=10, weight='bold')
plt.xticks(rotation=90, fontsize=10)
plt.grid(True, linestyle='--', alpha=0.7)

plt.show()


# На данной диаграме размаха визуализируется:
# - Медианное значение (наиболее частровстречающееся) суммы заказа является 22882 руб
#     
# - Межквартильный размах составляет от 12135 до 33730 руб - диапазон сумм заказов, с которыми были совершены наибольшее число заказов 
#     
# - Заказ с максимальной суммой 44995 руб, с минимальной - 1002
#     
# - Значения которые выходят за 1.5 межквартильных размаха считаются выбросами (аномальными заказами по сумме продаж). **На данном графике отсутствуют**
#     

# In[217]:


mean = df['sales'].mean()
std_dev = df['sales'].std()


# In[234]:


lower_bound_ = mean - 3 * std_dev
upper_bound_ = mean + 3 * std_dev

print(f"Нижняя граница (3 сигмы): {lower_bound_}")
print(f"Верхняя граница (3 сигмы): {upper_bound_}")


# Если данные в колонке sales находятся за пределами этих границ, это может указывать на наличие значительных выбросов или аномалий. Такие выбросы могут быть результатом ошибок в данных, редких событий или особых условий, которые требуют дальнейшего анализа.

# В данных отсутсвуют выбросы и аномалии, это подтверждено
# - методом describe
# - построением диаграммы размаха с отсутствием выбросов
# - правилом 3 сигм с нахождением диапазона "нормальности"

# #### Задание 3

# ##### Категоризация заказов по сумме

# На основании отсутсвия аномальных сумм заказов, логично будет разделить заказы по перцентилям

# In[235]:


df['sale_group'] = pd.qcut(df['sales'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])


# In[267]:


category_labels = {
    'Q1': 'Low Value',
    'Q2': 'Medium-Low Value',
    'Q3': 'Medium-High Value',
    'Q4': 'High Value'
}

df['sale_group'] = df['sale_group'].replace(category_labels)


# In[237]:


df.order_category.value_counts()


# In[238]:


df.sample(3)


# Получено 4 группы с одинаковым количеством наблюдений 

# ##### Сгруппировать данные на основе региона и группы продаж (Region, Sale_group). Определить основные тенденции и паттерны. Выделить наиболее «прибыльную» группу

# In[258]:


df_benefit = df \
          .groupby(['region', 'sale_group'], observed=True)\
          .agg({'order_date': 'count', 'sales': 'sum'})\
          .sort_values('sales',ascending = False)\
          .rename(columns = {'order_date':'order_num'})

df_benefit


# In[259]:


df_benefit['avg_order_amount'] = df_benefit['sales'] / df_benefit['order_num']


# In[260]:


df_benefit.sort_values('avg_order_amount',ascending = False,)


# Регионом с самой высокой средней суммой заказа являются Калининград
# Самые недорогие заказы делают покупатели из москвы.
# Урал и Москва делают меньшее число заказов, но с более высокими суммами, чем Калининград и Владивосток

# In[278]:


plt.figure(figsize=(12, 6))
sns.barplot(data=df_benefit, x='region', y='order_num', hue='sale_group', palette='viridis')

plt.title('Столбчатая диаграмма по количество заказов в разных регионах по ценовому сегменту заказа')
plt.xlabel('Регион')
plt.ylabel('Число заказов')
plt.ylim(350,900)

plt.tight_layout()
plt.show()


# На данной столбчатой диаграмме отображено количество заказов по регионам
# - У Москвы меньше всего заказов, у Калининграда - больше всего
# - Во Владивостоке и Москве больше всего заказов сделано в категории "высокая стоимость заказа"
# - В Калининграде преимущественно делаются заказы средней ценовой категории, а Во Владивостоке - низкой и высокой стоимости.
# - На Урале цисло заказов разных ценовых категорий практически одинаковые

# In[290]:


sales_by_group = df_benefit.groupby('sale_group', observed=True)['sales'].sum()


# Построение круговой диаграммы
plt.figure(figsize=(8, 8))
colors = sns.color_palette('pastel')  # Использование пастельной палитры из Seaborn
plt.pie(sales_by_group, labels=sales_by_group.index, autopct='%1.1f%%', colors=colors,wedgeprops={'lw':1, 'ls':'--','edgecolor':"k"})
plt.title('Распределение суммарных продаж по группам')

# Показать график
plt.show()


# На данной круговой диаграмме визуализируется, что 
# - 43% прибыли исходит от заказов высокой стоимости
# - 31% - средне-высокой стоимости
# - 7% - низкой
# - 19% средне-низкой

# ##### Проверка

# In[291]:


if df['sales'].sum() == df_benefit['sales'].sum():
    print('Ок, нет потерь данных')
else:
    print('Error')


# #### Финальный вывод по тестовому заданию

# <div style="border:solid Purple 2px; padding: 40px">
# 
# - Был произведен онбординг с датасетом при помощи универсальный функции, которая выводит первые 5 строк таблицы, количество пропусков, дубликатов, информацию о размере, а так же о типе данных столбцов.
#     
# - Выполнена преобработка данных с приведением столбцво в змеиный регистр, корректировкой типов данных некоторых столбцов, перепроверкой на наличие явных и неявных дубликатов
#     
# - Найден ответ на первое задание- определены подкатегории товаров, которые покупали максимально часто за все время, за последние 2 года от исследуемых данных и за последний год. Во всех 3 временных интервалах субкатегории 'Binders', 'Paper', 'Furnishings', 'Phones', 'Storage' обладали наивысшим количеством заказов. Визуализация с помощью хитмэпа
#     
# - Построена визуализация (диаграмма размаха). На ней отображено - медианное значение суммы заказа является 22882 руб, межквартильный размах составляет от 12135 до 33730 руб - диапазон наиболее частовстречающихся сумм заказов , с которыми были совершены наибольшее число заказов, максимальная сумма заказа составила 44995 руб, с минимальная - 1002 руб, аномальных значений не обнаружено
#     
# - Проведена перепроверка данных на нормальность методом describe, построением диаграммы размаха (с отсутствием выбросов) и правилом 3 сигм с нахождением диапазона "нормальности"
#     
# - Из-за отсутсвтия аномалий данных было принято решения сегментации данных по величине суммы заказа по перцентилям. В итоге выделено 4 группы: с низкой, средней, средне-высокой и высокой стоимостью. В каждую группу вошло 2450 наблюдений.
#     
# - Произведена группировка по региону и ценовому сегменту заказа и сортировка по величине суммы заказа. Далее в исследуемый датафрейм добавлен столбец со средней суммой заказа и выделены следующие паттерны: регионами с самой высокой средней суммой заказа является Калининград. Урал и Москва делают меньшее число заказов, но с более высокими суммами, чем Калининград и Владивосток. Именно заказы из Владивостока и калининграда являются наиболее прибыльными для компании.
# 
# - На столбчатой диаграме отмечается, что больше всего заказов делает калининград и относятся он с категории средне-низкой и средне-высокой стоимости, Москва делает меньшего всего общее количество заказов, но там наибольший процент заказов высокой стоимости
#     
# -43% прибыли исходит от заказов высокой стоимости, 31% - средне-высокой стоимости, 7% - низкой, 19% средне-низкой
# 
# 
# - Возможно, стоит провести определенные маркетинговые акции для привлечения клиентов именно из регионов Урал и Москва для повышения количества заказов, которые на основании исследуемых данных являются самыми крупными и приносят максимальное количество прибыли
# 
# - Возможно, при увеличении затрат на рекламные инвестиции в Урале и Москве получится увеличить количество заказов за счет привлечения новых пользователей или расширения аудитории покупателей 
# 
# - А в калиниграде и Владивостоке необходимо стимулировать клиентов на совершение более дорогих заказов за счет проведения маркетинговых кампаний
# </div>
# 
